<!DOCTYPE html>
<html>

<head>
  <title>PGX Top to Bottom</title>
  <meta charset="utf-8">
  <style>
    @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
    @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
    @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

    body {
      font-family: 'Droid Serif';
    }

    h1,
    h2,
    h3 {
      font-family: 'Yanone Kaffeesatz';
      font-weight: normal;
    }

    .remark-code,
    .remark-inline-code {
      font-family: 'Ubuntu Mono';
    }
  </style>
</head>

<body>
  <textarea id="source">

class: center, middle

# PGX Top to Bottom

29 Aug 2023

Jack Christensen

---

# Introduction

* Topic - advanced usage and architecture of pgx
* Target Audience - intermediate to advanced Go and PostgreSQL users
* Goal - everyone learns something they can use

Questions are welcome!

???

* There will be lots of code. Presentation source will be available. There are over 20 sample programs in the repo.
* Assumes knowledge of Go, PostgreSQL, and basic usage of pgx. For example,
discussion of stdlib will assume a little knowledge of the pgx interfaces before
pgx is discussed. We will be going top to bottom and pealing pgx like an onion.

---

# Primary Packages

* stdlib - `database/sql` compatibility
* pgxpool - connection pool
* pgx - primary interface for a single connection
* pgtype - type conversions between Go and PostgreSQL types
* pgconn - low-level connection interface similar to the C libpq library
* pgproto3 - wire protocol encoding and decoding

---

# stdlib - basics

```go
package main

import (
	"database/sql"
	"fmt"
	"log"
	"os"

	_ "github.com/jackc/pgx/v5/stdlib"
)

func main() {
	db, err := sql.Open("pgx", os.Getenv("DATABASE_URL"))
	if err != nil {
		log.Fatal(err)
	}
	defer db.Close()

	var n int32
	err = db.QueryRow("select 42").Scan(&n)
	if err != nil {
		log.Fatal(err)
	}

	fmt.Println(n)
}
```

---

# stdlib - pgx types as query parameters

Anything value the pgx driver can use can also be used through `database/sql`.

```go
	_, err = db.ExecContext(ctx, `
	create temporary table t (
		id int primary key generated by default as identity,
		data int[] not null
	)`)
	if err != nil {
		log.Fatal(err)
	}

	// Query arguments are passed directly to the underlying pgx conn so there is
	// no need to implement driver.Valuer if pgx already understands the type.
	_, err = db.ExecContext(ctx,
		`insert into t (data) values ($1)`,
		[]int32{1, 2, 3},
	)
	if err != nil {
		log.Fatal(err)
	}
```

---

# stdlib - pgx types as scan targets

```go
	// Scanning requires the use of an adapter.
	m := pgtype.NewMap()
	var data []int32
	err = db.QueryRow("select data from t limit 1").Scan(m.SQLScanner(&data))
	if err != nil {
		log.Fatal(err)
	}

	fmt.Println(data) // => [1 2 3]
```

Scanning through database/sql is limited by the sql.Scanner interface. The
underlying PostgreSQL type is lost. The underlying text or binary format is lost
as well. This means many types that pgx supports in binary format fall back to
text format when running through `database/sql`.

* `*pgtype.Map` needed as adapter
* Scan targets that have multiple possible PostgreSQL types will not work. For
example, `map[string]any` could come from PostgreSQL `json`, `jsonb`, or
`hstore`.
* Generic types such as `Array[T]` may not work.

---

# stdlib - custom connection config

```go
config, err := pgx.ParseConfig(os.Getenv("DATABASE_URL"))
if err != nil {
  log.Fatal(err)
}

config.OnNotice = func(c *pgconn.PgConn, n *pgconn.Notice) {
  log.Printf("PID: %d; Message: %s\n", c.PID(), n.Message)
}

db := stdlib.OpenDB(*config)
defer db.Close()

_, err = db.Exec("drop table if exists foo")
if err != nil {
  log.Fatal(err)
}

// config.OnNotice prints:
// => 2023/08/24 20:42:44 PID: 86890; Message: table "foo" does not exist, skipping
```

* `OpenDB` is simplest interface for customizing connection config
* `stdlib.RegisterConnConfig` is also available when using a 3rd party wrapper
that internally calls `sql.Open`.

---

# stdlib - getting a *pgx.Conn

PostgreSQL specific features that are not available through `database/sql` such
as `COPY` can be accessed by getting a `*pgx.Conn` from the `*sql.DB`.

```go
// Given db is a *sql.DB
conn, err := db.Conn(context.Background())
if err != nil {
  // handle error from acquiring connection from DB pool
}
//
err = conn.Raw(func(driverConn any) error {
  conn := driverConn.(*stdlib.Conn).Conn() // conn is a *pgx.Conn
  // Do pgx specific stuff with conn
  _, err := conn.CopyFrom(...)
  return err
})
if err != nil {
  // handle error that occurred while using *pgx.Conn
}
```

---

# stdlib - no special privileges

* `stdlib` is built on top of the `pgx` and `pgtype` packages.
* No special privileges or access to `pgx` internals.
* Less than 800 lines including comments.
* Less than 600 actual lines of code.
* Designed to modular and replaceable.

???

Easy to build alternative database/sql interface on top of pgx or pgconn if
desired for some reason.

---

# pgxpool

```go
func main() {
	ctx := context.Background()

	dbpool, err := pgxpool.New(ctx, os.Getenv("DATABASE_URL"))
	if err != nil {
		log.Fatal(err)
	}
	defer dbpool.Close()

	var n int32
	err = dbpool.QueryRow(ctx, "select $1::int", 42).Scan(&n)
	if err != nil {
		log.Fatal(err)
	}

	fmt.Println(n) // => 42
}
```

* Core pool logic provided by `github.com/jackc/puddle/v2`.

???

* puddle is a tiny generic resource pool.
* Even with Go concurrency is really hard. puddle encapsulates the hardest parts.

---

# pgxpool - features

Connection lifecycle callbacks:

* BeforeConnect
* AfterConnect
* BeforeAcquire
* AfterRelease
* BeforeClose

Pool size control:

* MinConns
* MaxConns
* MaxConnIdleTime
* MaxConnLifetime

---

# pgxpool - statistics

* AcquireCount
* AcquireDuration
* AcquiredConns
* CanceledAcquireCount
* ConstructingConns
* EmptyAcquireCount
* IdleConns
* TotalConns
* NewConnsCount
* MaxLifetimeDestroyCount
* MaxIdleDestroyCount

---

# pgxpool - escape hatches

* `*pgxpool.Conn` provides `Conn()` method to get the underlying `*pgx.Conn`.
* `*pgxpool.Conn` provides `Hijack()` method to take a connection from the pool
  permanently.

---

# pgxpool - no special privileges

* `pgxpool` is built on top of the `pgx` package.
* No special privileges or access to `pgx` internals.
* pgxpool is only ~800 lines of code.
* Designed to modular and replaceable.

???

* Did I mention concurrency is hard?
* No changes planned. High bar for any proposed changes.


---

# pgx - basics

```go
func main() {
	ctx := context.Background()

	conn, err := pgx.Connect(ctx, os.Getenv("DATABASE_URL"))
	if err != nil {
		log.Fatal(err)
	}
	defer conn.Close(ctx)

	var n int32
	err = conn.QueryRow(ctx, "select $1::int", 42).Scan(&n)
	if err != nil {
		log.Fatal(err)
	}

	fmt.Println(n) // => 42
}
```

* pgx is connection oriented.
* Basic interface mimics `database/sql` but with context by default (`Query`,
`QueryRow`, `Exec`).

???

Emphasize connection oriented. pgx is not a connection pool. But very similar
interface to pgxpool. Or really pgxpool has a very similar interface to pgx.

---

# pgx - database/sql style query interface

```go
var numbers []int32
rows, err := conn.Query(ctx, "select generate_series(1, 10)")
if err != nil {
  // Error check could be omitted as any error is included in rows.
  log.Fatal(err)
}

for rows.Next() {
  var n int32
  err = rows.Scan(&n)
  if err != nil {
    log.Fatal(err)
  }

  numbers = append(numbers, n)
}

if rows.Err() != nil {
  log.Fatal(err)
}

fmt.Println(numbers) // => [1 2 3 4 5 6 7 8 9 10]
```

???

* Verbose and error prone.
* Query only sends query to server. err may be nil even if query eventually
  fails.
* Frequent issue is forgetting to check rows.Err().

---

# pgx - CollectRows

```go
rows, _ := conn.Query(ctx, "select generate_series(1, 10)")
numbers, err := pgx.CollectRows(rows, func(row pgx.CollectableRow) (int32, error) {
  var n int32
  err := row.Scan(&n)
  return n, err
})
if err != nil {
  log.Fatal(err)
}

fmt.Println(numbers) // => [1 2 3 4 5 6 7 8 9 10]
```

* `CollectRows` is a generic function that takes a generic `RowToFunc[T]`.

???

Go generics are really useful in pgx.

---

# pgx - CollectRows implementation

```go
// RowToFunc is a function that scans or otherwise converts row to a T.
type RowToFunc[T any] func(row CollectableRow) (T, error)

// CollectRows iterates through rows, calling fn for each row, and collecting the results into a slice of T.
func CollectRows[T any](rows Rows, fn RowToFunc[T]) ([]T, error) {
	defer rows.Close()

	slice := []T{}

	for rows.Next() {
		value, err := fn(rows)
		if err != nil {
			return nil, err
		}
		slice = append(slice, value)
	}

	if err := rows.Err(); err != nil {
		return nil, err
	}

	return slice, nil
}
```

???

Note the defer rows.Close(). Our previous examples could leak if a panic occurred.

---

# pgx - generic RowTo

```go
rows, _ := conn.Query(ctx, "select generate_series(1, 10)")
numbers, err := pgx.CollectRows(rows, pgx.RowTo[int32])
if err != nil {
  log.Fatal(err)
}

fmt.Println(numbers) // => [1 2 3 4 5 6 7 8 9 10]
```

`RowTo` is a simple generic function as well.

```go
// RowTo returns a T scanned from row.
func RowTo[T any](row CollectableRow) (T, error) {
	var value T
	err := row.Scan(&value)
	return value, err
}
```

???

* Even better. Now we are down to two statements and an error check.

---

# pgx - builtin RowToFunc functions

* RowTo
* RowToAddrOf
* RowToMap
* RowToStructByPos
* RowToAddrOfStructByPos
* RowToStructByName
* RowToAddrOfStructByName
* RowToStructByNameLax
* RowToAddrOfStructByNameLax

???

Functions should be self-explanatory from their names except for Lax.

---

# pgx - struct mapping example

Given the following setup:

```go
	_, err = conn.Exec(ctx, `
		create temporary table users (
			id int primary key generated by default as identity,
			name text not null,
			email text not null
		)`)
	if err != nil {
		log.Fatal(err)
	}

	_, err = conn.Exec(ctx, `
		insert into users (name, email) values
			('Matthew', 'matthew@example.com'),
			('Mark', 'mark@example.com'),
			('Luke', 'luke@example.com'),
			('John', 'john@example.com'),
			('Mary', 'mary@example.com'),
			('Martha', 'martha@example.com')`)
	if err != nil {
		log.Fatal(err)
	}
```

---

# pgx - struct mapping example (continued)

```go
	type User struct {
		ID    int32
		Name  string
		Email string
	}

	rows, _ := conn.Query(ctx, "select id, name, email from users")
	users, err := pgx.CollectRows(rows, pgx.RowToStructByPos[User])
	if err != nil {
		log.Fatal(err)
	}

	for _, user := range users {
		fmt.Println(user)
	}

	// Output:
	//
	// {1 Matthew matthew@example.com}
	// {2 Mark mark@example.com}
	// {3 Luke luke@example.com}
	// {4 John john@example.com}
	// {5 Mary mary@example.com}
	// {6 Martha martha@example.com}
```

---

# pgxutil - Select and SelectRow

https://github.com/jackc/pgxutil is where I add personal convenience functions
and experiment with new ideas that may eventually make it into pgx.

`Select` makes this:

```go
	rows, _ := conn.Query(ctx, "select id, name, email from users")
	users, err := pgx.CollectRows(rows, pgx.RowToStructByPos[User])
```

become this:

```go
	users, err := pgxutil.Select(ctx, db, "select id, name, email from users",
    nil, pgx.RowToStructByPos[User])
```

It completely hides `Rows`.

???

I tend to use `Select` and `SelectRow` for most queries.

---

# pgx - ForEachRow

In the same way the `CollectRows` is an abstraction on collecting all the rows
of a query, `ForEachRow` is an abstraction on iterating through all the rows of
a query.

```go
rows, _ := conn.Query(ctx, "select generate_series(1, 5)")
var n int32
_, err = pgx.ForEachRow(rows, []any{&n}, func() error {
  fmt.Println(n)
  return nil
})
if err != nil {
  log.Fatal(err)
}

// Output:
//
// 1
// 2
// 3
// 4
// 5
```

???

* Less often used than `CollectRows`.
* Avoids the multiple statements and error checks of `Query`, `Next`, `Scan`,
  `rows.Err()`.
* Slightly awkward to declare scan targets outside of function
* May avoid allocating for every iteration when using complex scan targets.

---

# pgx - pseudo-nested transactions

```go
// Error handling omitted for brevity.

tx, err := conn.Begin(ctx)

_, err = tx.Exec(ctx, `insert into users (name, email) values
    ('Matthew', 'matthew@example.com')`)

tx2, err := tx.Begin(ctx)

_, err = tx2.Exec(ctx, `insert into users (name, email) values
    ('Mark', 'mark@example.com')`)

err = tx2.Rollback(ctx)

err = tx.Commit(ctx)

var n int32
err = conn.QueryRow(ctx, "select count(*) from users").Scan(&n)

fmt.Println(n) // => 1
```

---

# pgx - pseudo-nested transactions (continued)


* Nested transactions are simulated with savepoints.
* Savepoints should be used with care on production systems.
  * https://postgres.ai/blog/20210831-postgresql-subtransactions-considered-harmful
  * https://about.gitlab.com/blog/2021/09/29/why-we-spent-the-last-month-eliminating-postgresql-subtransactions/
* But nested transactions can be especially useful in tests. It allows the test
to be transactional (e.g. rolled back) while still testing transactional
behavior.

---

# pgx - BeginFunc

`BeginFunc` is a wrapper that automatically rolls back if an error is returned
and automatically commits if no error is returned.

```go
pgx.BeginFunc(ctx, conn, func(tx pgx.Tx) error {
  _, err = tx.Exec(ctx, `insert into users (name, email) values
    ('Matthew', 'matthew@example.com')`)
  if err != nil {
    return err
  }

  return nil
})
```

---

# pgx - Execution protocols and value formats

PostgreSQL has two ways to execute queries:

* Simple protocol - SQL string. Does not support parameterized queries (i.e. potentially unsafe). Only uses text format for results.
* Extended protocols - separate parse, bind, and execute steps. Supports parameterized queries. Can use binary format for results.

Value formats:

* Text - more understandable, but usually slower
* Binary - usually faster, but can be ambigous (e.g. 4 bytes could be int32 or float32)

pgx supports both protocols and both formats and prefers the faster binary format when possible.

???

* Text-like types are actually faster in text format.

---

# pgx - Execution protocols and value formats (continued)

The extended protocol allows the client to know the types of the parameters and
results. However, this requires two network round trips. One to parse and
describe the statement, and one to execute the statement.

pgx supports fine grained control over the prefered execution mode.

Modes where the value formats are known:

* QueryExecModeCacheStatement - internally prepare and cache statements - one round trip per query after first
* QueryExecModeCacheDescribe - cache description of statement without preparing - one round trip per query after first
* QueryExecModeDescribeExec - uses two round trips per query

Modes where the value formats are not known:

* QueryExecModeExec - single round trip in extended protocol
* QueryExecModeSimpleProtocol - single round trip in simple protocol

???

* These formats can be set for a connection default or per query.

---

# pgx - Batched queries

Network latency can be a significant factor in performance. pgx supports batched
queries that minimize network round trips.

```go
batch := &pgx.Batch{}
batch.Queue("insert into users (name, email) values ($1, $2)", "Matthew", "matthew@example.com")
batch.Queue("insert into users (name, email) values ($1, $2)", "Mark", "mark@example.com")
err = conn.SendBatch(ctx, batch).Close()
if err != nil {
  log.Fatal(err)
}
```

???

Obviously, a single insert statement with multiple rows could have been done instead in this case. But it shows the basic idea.

---

# pgx - Batched queries (continued)

```go
	batch := &pgx.Batch{}
	batch.Queue("select 'foo'").QueryRow(func(row pgx.Row) error {
		var s string
		err := row.Scan(&s)
		if err != nil {
			return err
		}
		fmt.Println(s) // => foo
		return nil
	})
	batch.Queue("select 'bar'").QueryRow(func(row pgx.Row) error {
		var s string
		err := row.Scan(&s)
		if err != nil {
			return err
		}
		fmt.Println(s) // => foo
		return nil
	})
	err = conn.SendBatch(ctx, batch).Close()
	if err != nil {
		log.Fatal(err)
	}

	// Output:
	//
	// foo
	// bar
```

???

* Callbacks can be registered for each queued query.
* The result of SendBatch can be iterated and the results handled there, but in most cases the callbacks are more convenient.

---

# pgx - Batched queries (continued)

* Batches are implicitly transactional. If any query in the batch fails the entire batch is rolled back.
* There are limits on the number of queries that can be batched together.
* Unfortunately, these limits vary and are not clearly defined.
* If read and write network buffers are filled a delay may occur until pgx notices the deadlock and starts a background read to unblock it.
* Implicit transactions seem to have some sort of memory limit in PostgreSQL. Users have reported PostgreSQL errors with very large batches.
* 1000 queries seems to be a good size that balances performance with staying well away from the limits.

---

# pgx - other advanced or lesser known features

* `CopyFrom` should be preferred for bulk inserts. It is significantly faster
  than insert even for as few as 5 rows.
* `WaitForNotification` is a convenient
  way to listen for PostgreSQL notifications. It buffers notifications internally
  so it is safe to use a single connection for queries and to occasionally check
  for notifications.
* Tracing interfaces are provided for logging and to allow integration with projects like OpenTelemetry.
* Large object support.

???

* Large objects -- for when you want PostgreSQL to be your file system.

---

# pgx - no special privileges and escape hatches

* No privileged access to pgconn or pgtype.
* Conn.TypeMap() gives access to underlying pgtype system
* Conn.PgConn() gives access to underlying pgconn system

???

* Recurring theme - pgx is modular and built in layers

---

# pgtype - overview

pgtype is responsible for converting between Go and PostgreSQL types.

## Key concepts

* PostgreSQL types are identified by OID (object ID)
* `Map` is the primary interface responsible for encoding parameters and decodings results
* A `Codec` is registered with a `Map` for a specific OID.
* A `Codec` does not directly encode or decode values. It returns an `EncodePlan` or a `ScanPlan`.
* A `Codec` typically exposes custom `*Scanner` and `*Valuer` interfaces for easy extension.

???

* The largest pgx component
* Rather complicated

---

# pgtype - Extending a built-in type

```go
type CircleF32 struct {
	X float32
	Y float32
	R float32
}

func (c *CircleF32) ScanCircle(v pgtype.Circle) error {
	if !v.Valid {
		return fmt.Errorf("cannot scan null circle")
	}

	c.X = float32(v.P.X)
	c.Y = float32(v.P.Y)
	c.R = float32(v.R)

	return nil
}

func (c CircleF32) CircleValue() (pgtype.Circle, error) {
	return pgtype.Circle{
		P: pgtype.Vec2{
			X: float64(c.X),
			Y: float64(c.Y),
		},
		R:     float64(c.R),
		Valid: true,
	}, nil
}
```

???

* CircleF32 uses float32 instead of float64 and cannot be null

---

# pgtype - Extending a built-in type (continued)

```go
var c CircleF32
err = conn.QueryRow(ctx, "select '<(3,4),2>'::circle").Scan(&c)
if err != nil {
  log.Fatal(err)
}

fmt.Println(c.X, c.Y, c.R) // => 3 4 2
```

???

* This allows custom types to be encoded as query parameters and scanned from
query results without needing to parse from or format to the PostgreSQL text or
binary formats for that type.

---

# pgtype - Adding a new Codec

* Codecs can be registered for new types
* Codecs for existing types can be replaced
* Codecs can be fairly complicated
  * Plan(s) to encode binary
  * Plan(s) to encode text
  * Plan(s) to scan binary
  * Plan(s) to scan text
  * Type and interfaces for easy extension
* The CircleCodec is ~200 lines of code

???

* It should be rare to need to add a new codec. But it is possible.
* The entire type system can be overridden if desired.
* If you want to create a Codec I suggest reading the package docs for pgtype
  and then looking at the source for one of the simple built-in types like CircleCodec.

---

# pgtype - the plan system

Wouldn't it be nice if these types were could directly be used without implementing `Scan` or `Value` like in `database/sql`?

```go
type Tag string

var tags []Tag
err = conn.QueryRow(ctx, "select array['foo', 'bar', 'baz']").Scan(&tags)
if err != nil {
  log.Fatal(err)
}

fmt.Println(tags) // => [foo bar baz]
```

* In pgx they can be!
* plans provide the flexibility and the performance

---

# pgtype - the plan system (continued)

If a Go value is not supported directly by a Codec then Map will try wrapping it with additional logic and try again.

```go
func NewMap() *Map {
  // ...

	return &Map{
		// ...
		TryWrapEncodePlanFuncs: []TryWrapEncodePlanFunc{
			TryWrapDerefPointerEncodePlan,
			TryWrapBuiltinTypeEncodePlan,
			TryWrapFindUnderlyingTypeEncodePlan,
			TryWrapStructEncodePlan,
			TryWrapSliceEncodePlan,
			TryWrapMultiDimSliceEncodePlan,
			TryWrapArrayEncodePlan,
		},

		TryWrapScanPlanFuncs: []TryWrapScanPlanFunc{
			TryPointerPointerScanPlan,
			TryWrapBuiltinTypeScanPlan,
			TryFindUnderlyingTypeScanPlan,
			TryWrapStructScanPlan,
			TryWrapPtrSliceScanPlan,
			TryWrapPtrMultiDimSliceScanPlan,
			TryWrapPtrArrayScanPlan,
		},
	}
}
```

---

# pgtype - the plan system (continued)

* These "try wrap" functions are tried in order and recursively.
* This allows supporting many types without the Codec needing to know about
them.
* It also could be slow to try so many options. That is the other side of the
"plan" system. Plans are cached internally by `Map`. So the expensive planning
process is only done once per type.
* Types can be seamlessly integrated without modification by adding "try wrap"
functions that directly look for that type. e.g. `time.Duration`,
`shopspring/decimal`, `github.com/gofrs/uuid`, etc.
* Code can be somewhat daunting. See https://github.com/jackc/pgx-gofrs-uuid/ for example.

---

# pgtype - arrays and composite types

```go
_, err = conn.Exec(ctx, `
create table teams (
  name text primary key
);

create table players (
  team_name text references teams(name),
  name text,
  number int
);

insert into teams (name) values ('Bulls');
insert into players (team_name, name, number) values
  ('Bulls', 'Michael Jordan', 23),
  ('Bulls', 'Scottie Pippen', 33),
  ('Bulls', 'Dennis Rodman', 91);
`)
```

???

Note that multiple statements are given in a single Exec. This works if there
are no parameters because Exec automatically uses the simple protocol.

---

# pgtype - arrays and composite types

Wouldn't it be nice if this worked?

```go
type Team struct {
	Name    string
	Players []*Player
}

type Player struct {
	Name   string
	Number int32
}
```

```go
var team Team
err = conn.QueryRow(ctx, `
  select name, (
    select array_agg(row(name, number) order by name)
    from players
    where team_name = teams.name
  ) as players
  from teams
  where name = 'Bulls'`,
).Scan(&team.Name, &team.Players)
```

???

Sorry this example gets split among many slides.

---

# pgtype - arrays and composite types

Arrays and composite types (usually) just work!

```go
fmt.Println(team.Name)
for _, player := range team.Players {
  fmt.Println(player.Name, player.Number)
}

// Output:
// Bulls
// Dennis Rodman 91
// Michael Jordan 23
// Scottie Pippen 33
```

* Can be simpler than an ORM or batching to load an object graph. Potentially
better performance as well.
* PostgreSQL `record` / `row` type usually requires the extended protocol and
binary format.

---

# pgtype - miscellaneous

* pgtype works with byte slices, OIDs, and Go values (i.e. it's decoupled from
pgx and pgconn)
* `Map.RegisterDefaultPgType` allows registering a presumed PostgreSQL type for
a Go type for when the PostgreSQL type is unknown (such as using the simple
protocol)
* `pgx.Conn.LoadType()` + `pgtype.Map.RegisterType()` allows registering custom
types like enums or composites.

---

# pgconn - introduction

* Similar to the C libpq.
* Low-level connection interface.
* Does not do any type conversions. Uses OIDs and `[]byte` directly.
* Rarely used directly.
* But some features are only available at this very low level.

---

# pgconn - introduction

```go
conn, err := pgconn.Connect(ctx, os.Getenv("DATABASE_URL"))
if err != nil {
  log.Fatal(err)
}
defer conn.Close(ctx)

mrr := conn.Exec(ctx, `
  select 'Hello, world';
  select 'Goodbye, world';`,
)
for mrr.NextResult() { // loop through each result set
  for mrr.ResultReader().NextRow() { // loop through each row in the result set
    row := mrr.ResultReader().Values()
    fmt.Println(string(row[0]))
  }
}
err = mrr.Close()
if err != nil {
  log.Fatal(err)
}
```

???

* Connection is basically the same as pgx, pgxpool, and stdlib. Core logic is here and they only layer onto it.
* Uses the simple protocol. Multiple queries can be included in a single Exec.

---

# pgconn - extended protocol

```go
	rr := conn.ExecParams(ctx,
		`select n, n::float * 1.1, n::float * 1.1 from generate_series(1, $1) n;`,
		[][]byte{[]byte("3")}, // param values
		nil,                   // param OIDs (let PostgreSQL infer them)
		nil,                   // param formats (defaults to text)
		[]int16{0, 0, 1},      // result formats (text, text, binary)
	)

	for rr.NextRow() {
		row := rr.Values()
		fmt.Printf(
			"%v (%v), %v (%v), %v\n",
			row[0], string(row[0]), row[1], string(row[1]), row[2],
		)
	}
	commandTag, err := rr.Close()
	if err != nil {
		log.Fatal(err)
	}
	fmt.Println(commandTag)

	// Output:
	//
	// [49] (1), [49 46 49] (1.1), [63 241 153 153 153 153 153 154]
	// [50] (2), [50 46 50] (2.2), [64 1 153 153 153 153 153 154]
	// [51] (3), [51 46 51 48 48 48 48 48 48 48 48 48 48 48 48 48 48 51] (3.3000000000000003), [64 10 102 102 102 102 102 103]
	// SELECT 3
```

???

* Extended protocol safely separates parameters from query text.
* Control over exactly how parameters and results are encoded and decoded.

---

# pgconn - pipeline mode

* Precise control over when network round trips occur.
* Can be very verbose
* Queries are not sent until `Sync` is called.

```go
pipeline := conn.StartPipeline(ctx)
pipeline.SendQueryParams(`select 1`, nil, nil, nil, nil)
pipeline.SendQueryParams(`select 2`, nil, nil, nil, nil)
pipeline.SendQueryParams(`select 3`, nil, nil, nil, nil)
err = pipeline.Sync()
if err != nil {
  log.Fatal(err)
}
```

---

# pgconn - pipeline mode (continued)

```go
// Query 1

results, err := pipeline.GetResults()
if err != nil {
  log.Fatal(err)
}

rr, ok := results.(*pgconn.ResultReader)
if !ok {
  log.Fatalf("expected ResultReader, got: %#v", results)
}

for rr.NextRow() {
  row := rr.Values()
  fmt.Println(string(row[0])) // 1
}
commandTag, err := rr.Close()
if err != nil {
  log.Fatal(err)
}
fmt.Println(commandTag) // SELECT 1
```

---

# pgconn - pipeline mode (continued)

```go
// Query 2

results, err = pipeline.GetResults()
if err != nil {
  log.Fatal(err)
}

rr, ok = results.(*pgconn.ResultReader)
if !ok {
  log.Fatalf("expected ResultReader, got: %#v", results)
}

for rr.NextRow() {
  row := rr.Values()
  fmt.Println(string(row[0])) // 2
}
commandTag, err = rr.Close()
if err != nil {
  log.Fatal(err)
}
fmt.Println(commandTag) // SELECT 1
```

---

# pgconn - pipeline mode (continued)

```go
// Query 3

results, err = pipeline.GetResults()
if err != nil {
  log.Fatal(err)
}

rr, ok = results.(*pgconn.ResultReader)
if !ok {
  log.Fatalf("expected ResultReader, got: %#v", results)
}

for rr.NextRow() {
  row := rr.Values()
  fmt.Println(string(row[0])) // 3
}
commandTag, err = rr.Close()
if err != nil {
  log.Fatal(err)
}
fmt.Println(commandTag) // SELECT 1
```

---

# pgconn - pipeline mode (continued)

```go
// Sync response

results, err = pipeline.GetResults()
if err != nil {
  log.Fatal(err)
}

_, ok = results.(*pgconn.PipelineSync)
if !ok {
  log.Fatalf("expected ResultReader, got: %#v", results)
}
```

???

Note that `GetResults` can return multiple types.

---

# pgconn - pipeline mode (continued)

```go
	// Send more queries

	pipeline.SendQueryParams(`select 4`, nil, nil, nil, nil)
	pipeline.SendQueryParams(`select 5`, nil, nil, nil, nil)
	err = pipeline.Sync()
	if err != nil {
		log.Fatal(err)
	}
```

---

# pgconn - pipeline mode (continued)

* Reading those results is omitted.
* Finally close the pipeline to return the connection to normal operation.

```go
	err = pipeline.Close()
	if err != nil {
		log.Fatal(err)
	}
```

* Used to implement pgx batching.
* Can also prepare and deallocate statements.
* Nearly but not quite at the level of individual protocol messages over the wire.
* Requires a fair amount of understanding of the PostgreSQL protocol.

???

* Did I mention it is very verbose?

---

## pgconn - copy

* `CopyFrom` and `CopyTo` directly expose `io.Reader` and `io.Writer` interfaces to
  the PostgreSQL copy protocol.
* Callers are responsible for formatting or parsing the data.
* Can be used to copy data between PostgreSQL servers.

```go
	r, w := io.Pipe()
	errChan := make(chan error)
	go func() {
		_, err := sourceDBConn.CopyTo(ctx, w, "copy (select ...) to stdout")
		w.Close()
		errChan <- err
	}()

	_, err := destDBConn.CopyFrom(ctx, r, "copy tablename from stdin")
	if err != nil {
		return fmt.Errorf("copy from failed: %w", err)
	}
	err = <-errChan
	if err != nil {
		return fmt.Errorf("copy to failed: %w", err)
	}
```

???

Example adapted from actual use.

---

# pgconn - escape hatches

* `Frontend()` allows direct access to the underlying `pgproto3.Frontend`.
* `ReceiveMessage` allows directly reading a message from the server.
* `Conn()` allows direct access to the underlying `net.Conn`.
* `Hijack()` exposes internal state such as `PID` and `SecretKey` and takes over the `net.Conn`.

???

* These are rarely needed. But they are available if needed.
* Hijack in particular would allow another database driver to be bootstrapped on
top of pgconn. It could use pgconn to handle the connection and authentication
process and then take over.
* SecretKey is used to cancel queries.

---

# pgproto3 - introduction

* pgproto3 handles parsing and encoding of the PostgreSQL wire protocol.
* Typical client applications should rarely if ever need to use it directly.
* It can be useful for implementing load balancers, proxies, or other PostgreSQL middleware.

---

# pgproto3 - debug tracing

```go
conn.Frontend().Trace(os.Stdout, pgproto3.TracerOptions{
  SuppressTimestamps: true,
  RegressMode:        true,
})

mrr := conn.Exec(ctx, `
  select 'Hello, world';
  select 'Goodbye, world';`,
)
err = mrr.Close()
if err != nil {
  log.Fatal(err)
}
```

```
F	Query	58	 "
		select 'Hello, world';
		select 'Goodbye, world';"
B	RowDescription	34	 1 "?column?" 0 0 25 -1 -1 0
B	DataRow	23	 1 12 'Hello, world'
B	CommandComplete	14	 "SELECT 1"
B	RowDescription	34	 1 "?column?" 0 0 25 -1 -1 0
B	DataRow	25	 1 14 'Goodbye, world'
B	CommandComplete	14	 "SELECT 1"
B	ReadyForQuery	6	 I
```

???

* F = frontend
* B = backend

---

# pgproto3 - debug tracing (continued)

```go
	rr := conn.ExecParams(ctx,
		`select n, n::float * 1.1, n::float * 1.1 from generate_series(1, $1) n;`,
		[][]byte{[]byte("3")}, // param values
		nil,                   // param OIDs (let PostgreSQL infer them)
		nil,                   // param formats (defaults to text)
		[]int16{0, 0, 1},      // result formats (text, text, binary)
	)
	_, err = rr.Close()
	if err != nil {
		log.Fatal(err)
	}
```

```
F	Parse	80	 "" "select n, n::float * 1.1, n::float * 1.1 from generate_series(1, $1) n;" 0
F	Bind	24	 "" "" 0 1 '3' 3 0 0 1
F	Describe	7	 P ""
F	Execute	10	 "" 0
F	Sync	5
B	ParseComplete	5
B	BindComplete	5
B	RowDescription	81	 3 "n" 0 0 23 4 -1 0 "?column?" 0 0 701 8 -1 0 "?column?" 0 0 701 8 -1 1
B	DataRow	31	 3 1 '1' 3 '1.1' 8 '?\xf1\x99\x99\x99\x99\x99\x9a'
B	DataRow	31	 3 1 '2' 3 '2.2' 8 '@\x1\x99\x99\x99\x99\x99\x9a'
B	DataRow	46	 3 1 '3' 18 '3.3000000000000003' 8 '@\xafffffg'
B	CommandComplete	14	 "SELECT 3"
B	ReadyForQuery	6	 I
```

???

* Notice the difference between the simple and extended protocols.
* Also the difference between text and binary formats.
* Useful for debugging and developing pgx itself.
* Also sometimes useful for confirming exactly what is happening over the wire.

---

# pgproto3 - pgfortune example

```
jack@127.0.0.1:15432 jack=# select 'What?';
                  fortune
────────────────────────────────────────────
  ________________________________________ ↵
 / It's very inconvenient to be mortal -- \↵
 | you never know when everything may     |↵
 \ suddenly stop happening.               /↵
  ---------------------------------------- ↵
  \     /\  ___  /\                        ↵
   \   // \/   \/ \\                       ↵
      ((    O O    ))                      ↵
       \\ /     \ //                       ↵
        \/  | |  \/                        ↵
         |  | |  |                         ↵
         |  | |  |                         ↵
         |   o   |                         ↵
         | |   | |                         ↵
         |m|   |m|                         ↵

(1 row)
```

???

* This brings us back to the beginning. pgproto3 is used to implement a simple mock PostgreSQL server that responds with `fortune | cowsay`.
* Source is in pgx repo under the pgproto3/example/pgfortune.
* Look at source code if there is time.

---

# Thank You!

Source code and slides: https://github.com/jackc/pgx-top-to-bottom




    </textarea>
  <script src="https://remarkjs.com/downloads/remark-latest.min.js">
  </script>
  <script>
    var slideshow = remark.create();
  </script>
</body>

</html>
